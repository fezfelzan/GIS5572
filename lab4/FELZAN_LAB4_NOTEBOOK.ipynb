{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Felzan\n",
    "\n",
    "Arc II\n",
    "\n",
    "Lab 4 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.) GENERAL INITIALIZATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.) Importing Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "import requests\n",
    "import io\n",
    "from io import StringIO\n",
    "import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.) Manually inputting the path to the base of script users working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_base = r'C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV' # input the repo you want to\n",
    "                                                                  # 'house' the NDAWN folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.) Grabbing current date from the datetime module; creating a new folder for today's date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterightnow = datetime.datetime.now()\n",
    "formatteddate = daterightnow.strftime(\"%Y-%m-%d\")  \n",
    "\n",
    "currentdaywkdirpath = os.path.join(repo_base, formatteddate + \"_NDAWN\")\n",
    "os.mkdir(currentdaywkdirpath)\n",
    "wkdir = currentdaywkdirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\\\\\Users\\\\\\\\michaelfelzan\\\\\\\\Documents\\\\\\\\arc ii lab IV\\\\2021-04-21_NDAWN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) DIRECTORY/ STATION DICTIONARY INITIALIZATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.) Setting up dictionaries / lists to house all relevant info about every station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (I found this URL by clicking somewhere on the NDAWN website in Lab 1; the URL contains every station number/ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ndawn.ndsu.nodak.edu/get-table.html?station=78&station=111&station=98&station=142&station=138&station=9&station=10&station=118&station=56&station=11&station=12&station=58&station=13&station=84&station=55&station=7&station=87&station=14&station=15&station=96&station=16&station=137&station=124&station=17&station=85&station=140&station=134&station=18&station=136&station=65&station=104&station=99&station=19&station=129&station=20&station=101&station=81&station=21&station=97&station=22&station=75&station=2&station=139&station=23&station=62&station=86&station=24&station=89&station=126&station=93&station=90&station=25&station=83&station=107&station=77&station=26&station=70&station=127&station=27&station=132&station=28&station=29&station=30&station=31&station=102&station=32&station=119&station=4&station=80&station=33&station=59&station=105&station=82&station=34&station=72&station=135&station=35&station=76&station=120&station=141&station=109&station=36&station=79&station=71&station=37&station=38&station=39&station=130&station=73&station=40&station=41&station=54&station=69&station=113&station=128&station=42&station=43&station=103&station=116&station=88&station=114&station=3&station=64&station=115&station=67&station=44&station=133&station=106&station=100&station=121&station=45&station=46&station=61&station=66&station=74&station=60&station=125&station=8&station=47&station=122&station=108&station=5&station=48&station=68&station=49&station=50&station=91&station=117&station=63&station=51&station=6&station=52&station=92&station=112&station=131&station=123&station=95&station=53&station=57&station=110&variable=mdsr&dfn=&dfy=&year=2020&ttype=monthly&quick_pick=&begin_date=2020-02&count=12'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stations_URL = \"https://ndawn.ndsu.nodak.edu/get-table.html?station=78&station=111&station=98&station=142&station=138&station=9&station=10&station=118&station=56&station=11&station=12&station=58&station=13&station=84&station=55&station=7&station=87&station=14&station=15&station=96&station=16&station=137&station=124&station=17&station=85&station=140&station=134&station=18&station=136&station=65&station=104&station=99&station=19&station=129&station=20&station=101&station=81&station=21&station=97&station=22&station=75&station=2&station=139&station=23&station=62&station=86&station=24&station=89&station=126&station=93&station=90&station=25&station=83&station=107&station=77&station=26&station=70&station=127&station=27&station=132&station=28&station=29&station=30&station=31&station=102&station=32&station=119&station=4&station=80&station=33&station=59&station=105&station=82&station=34&station=72&station=135&station=35&station=76&station=120&station=141&station=109&station=36&station=79&station=71&station=37&station=38&station=39&station=130&station=73&station=40&station=41&station=54&station=69&station=113&station=128&station=42&station=43&station=103&station=116&station=88&station=114&station=3&station=64&station=115&station=67&station=44&station=133&station=106&station=100&station=121&station=45&station=46&station=61&station=66&station=74&station=60&station=125&station=8&station=47&station=122&station=108&station=5&station=48&station=68&station=49&station=50&station=91&station=117&station=63&station=51&station=6&station=52&station=92&station=112&station=131&station=123&station=95&station=53&station=57&station=110&variable=mdsr&dfn=&dfy=&year=2020&ttype=monthly&quick_pick=&begin_date=2020-02&count=12\"\n",
    "all_stations_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting the station numbers from the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['station=78',\n",
       " 'station=111',\n",
       " 'station=98',\n",
       " 'station=142',\n",
       " 'station=138',\n",
       " 'station=9',\n",
       " 'station=10',\n",
       " 'station=118']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontslice = all_stations_URL.split('get-table.html?')[1]\n",
    "stationslice = frontslice.split('&variable=mdsr')[0]\n",
    "split_stations = stationslice.split(\"&\")\n",
    "\n",
    "split_stations[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating list of *just* the station numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['78',\n",
       " '111',\n",
       " '98',\n",
       " '142',\n",
       " '138',\n",
       " '9',\n",
       " '10',\n",
       " '118',\n",
       " '56',\n",
       " '11',\n",
       " '12',\n",
       " '58',\n",
       " '13']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_stationnumbers = []\n",
    "\n",
    "for stationequals in split_stations:\n",
    "    splitatequals = stationequals.split(\"=\")\n",
    "    just_stationnumbers.append(splitatequals[1])\n",
    "\n",
    "just_stationnumbers[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(just_stationnumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.) Iteratively sending requests to NDAWN server for each of the station numbers (via inputting the station numbers into the URL parameters) to receive the city/state that corresponds to each station number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info_url_base = \"https://ndawn.ndsu.nodak.edu/station-info.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ada, MN'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def StationNameGetter(splitstation):\n",
    "    full_url = station_info_url_base+\"?\"+splitstation\n",
    "    html_text = (requests.get(full_url)).text\n",
    "    frontslice = html_text.split(\"<h1>NDAWN Station: \")[1]\n",
    "    clean_name = frontslice.split(\"</h1>\")[0]\n",
    "    return clean_name\n",
    "\n",
    "StationNameGetter('station=78')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using 'StationNameGetter' function created above to request the city/state names which correspond to each station number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'station 78': 'Ada, MN', 'station 111': 'Adams, ND', 'station 98': 'Alamo, ND', 'station 142': 'Amidon, ND', 'station 138': 'Arnegard, ND', 'station 9': 'Baker, ND', 'station 10': 'Beach, ND', 'station 118': 'Becker, MN', 'station 56': 'Berthold, ND', 'station 11': 'Bismarck, ND', 'station 12': 'Bottineau, ND', 'station 58': 'Bowbells, ND', 'station 13': 'Bowman, ND', 'station 84': 'Brampton, ND', 'station 55': 'Britton, SD', 'station 7': 'Brorson, MT', 'station 87': 'Campbell, MN', 'station 14': 'Cando, ND', 'station 15': 'Carrington, ND', 'station 96': 'Carson, ND', 'station 16': 'Cavalier, ND', 'station 137': 'Charbonneau, ND', 'station 124': 'Clarissa, MN', 'station 17': 'Columbus, ND', 'station 85': 'Cooperstown, ND', 'station 140': 'Courtenay, ND', 'station 134': 'Crane Creek, ND', 'station 18': 'Crary, ND', 'station 136': 'Croff, ND', 'station 65': 'Crosby, ND', 'station 104': 'Crystal, ND', 'station 99': 'Dagmar, MT', 'station 19': 'Dazey, ND', 'station 129': 'Denhoff, ND', 'station 20': 'Dickinson, ND', 'station 101': 'Dooley, MT', 'station 81': 'Dunn, ND', 'station 21': 'Edgeley, ND', 'station 97': 'Edmore, ND', 'station 22': 'Egeland, ND', 'station 75': 'Ekre, ND', 'station 2': 'Eldred, MN', 'station 139': 'Epping, ND', 'station 23': 'Fargo, ND', 'station 62': 'Fingal, ND', 'station 86': 'Finley, ND', 'station 24': 'Forest River, ND', 'station 89': 'Fort Yates, ND', 'station 126': 'Fortuna, ND', 'station 93': 'Fox, MN', 'station 90': 'Froid, MT', 'station 25': 'Galesburg, ND', 'station 83': 'Garrison, ND', 'station 107': 'Genoa, ND', 'station 77': 'Grafton, ND', 'station 26': 'Grand Forks, ND', 'station 70': 'Greenbush, MN', 'station 127': 'Grenora, ND', 'station 27': 'Harvey, ND', 'station 132': 'Hawkeye, ND', 'station 28': 'Hazen, ND', 'station 29': 'Hettinger, ND', 'station 30': 'Hillsboro, ND', 'station 31': 'Hofflund, ND', 'station 102': 'Hope, ND', 'station 32': 'Horace, ND', 'station 119': 'Hubbard, MN', 'station 4': 'Humboldt, MN', 'station 80': 'Inkster, ND', 'station 33': 'Jamestown, ND', 'station 59': 'Karlsruhe, ND', 'station 105': 'Kempton, ND', 'station 82': 'Kennedy, MN', 'station 34': 'Langdon, ND', 'station 72': 'Leonard, ND', 'station 135': 'Liberty, ND', 'station 35': 'Linton, ND', 'station 76': 'Lisbon, ND', 'station 120': 'Little Falls, MN', 'station 141': 'Logan Center, ND', 'station 109': 'Maddock, ND', 'station 36': 'Mandan, ND', 'station 79': 'Marion, ND', 'station 71': 'Mavie, MN', 'station 37': 'Mayville, ND', 'station 38': 'McHenry, ND', 'station 39': 'McLeod, ND', 'station 130': 'Medicine Hole, ND', 'station 73': 'Michigan, ND', 'station 40': 'Minot, ND', 'station 41': 'Mohall, ND', 'station 54': 'Mooreton, ND', 'station 69': 'Mott, ND', 'station 113': 'Niles, ND', 'station 128': 'Noonan, ND', 'station 42': 'Northwood, ND', 'station 43': 'Oakes, ND', 'station 103': 'Ottertail, MN', 'station 116': 'Parkers Prairie, MN', 'station 88': 'Pekin, ND', 'station 114': 'Perham, MN', 'station 3': 'Perley, MN', 'station 64': 'Pillsbury, ND', 'station 115': 'Pine Point, MN', 'station 67': 'Plaza, ND', 'station 44': 'Prosper, ND', 'station 133': 'Rat Lake, ND', 'station 106': 'Ray, ND', 'station 100': 'Redstone, MT', 'station 121': 'Rice, MN', 'station 45': 'Robinson, ND', 'station 46': 'Rolla, ND', 'station 61': 'Roseau, MN', 'station 66': 'Ross, ND', 'station 74': 'Rugby, ND', 'station 60': 'Sabin, MN', 'station 125': 'Sawyer, ND', 'station 8': 'Sidney, MT', 'station 47': 'St. Thomas, ND', 'station 122': 'Staples, MN', 'station 108': 'Steele, ND', 'station 5': 'Stephen, MN', 'station 48': 'Streeter, ND', 'station 68': 'Tappen, ND', 'station 49': 'Towner, ND', 'station 50': 'Turtle Lake, ND', 'station 91': 'Ulen, MN', 'station 117': 'Wadena, MN', 'station 63': 'Wahpeton, ND', 'station 51': 'Walhalla, ND', 'station 6': 'Warren, MN', 'station 52': 'Watford City, ND', 'station 92': 'Waukon, MN', 'station 112': 'Webster, ND', 'station 131': 'Werner, ND', 'station 123': 'Westport, MN', 'station 95': 'Williams, MN', 'station 53': 'Williston, ND', 'station 57': 'Wishek, ND', 'station 110': 'Zeeland, ND'}\n"
     ]
    }
   ],
   "source": [
    "station_names = {}\n",
    "\n",
    "for station in split_stations:\n",
    "    iter_station = station.replace(\"=\", \" \")\n",
    "    iter_name = StationNameGetter(station)\n",
    "    station_names[iter_station] = iter_name\n",
    "\n",
    "print(station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hope, ND'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_names[\"station 102\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F.) Writing a CSV file at base of directory which contains all station numbers and their city/state names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationnamez = os.path.join(repo_base, \"stationnamez.csv\")\n",
    "\n",
    "with open(stationnamez, \"w\", newline=\"\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for key, value in (list(station_names.items())):\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G.) Creating a 'STATIONS' folder at the base of working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsfolderpath = os.path.join(wkdir, 'STATIONS')\n",
    "os.mkdir(stationsfolderpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H.) Iteratively creating folders inside STATIONS folder for each of the stations (named by just their station #):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    nameoffolder = os.path.join(stationsfolderpath, stationnum)\n",
    "    os.mkdir(nameoffolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) REQUESTING AND SEQUESTERING AVE. TEMPERATURE DATA FOR THE PAST 30 DAYS FOR EACH WEATHER STATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.) Iterating over list of stations and sending requests to NDAWN to retrieve average temperature data for each station for the past 30 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndawn_csvtable_urlbase = \"https://ndawn.ndsu.nodak.edu/table.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    foldpath = os.path.join(stationsfolderpath, stationnum)\n",
    "    master_params = {\n",
    "        \"station\" : stationnum,\n",
    "        \"variable\" : \"ddavt\",\n",
    "        \"dfn\" : \"\",\n",
    "        \"year\" : \"2021\",      # NDAWN has a built-in option to\n",
    "        \"ttype\" : \"daily\",    # \"quickpick\" the past 30 days' data\n",
    "        \"quick_pick\" : \"30_d\",        # Past 30 days,\n",
    "        \"begin_date\" : formatteddate}  # Based on current date.\n",
    "    \n",
    "    reqreq = requests.get(ndawn_csvtable_urlbase,\n",
    "                          params = master_params)\n",
    "    \n",
    "    csvname = os.path.join(foldpath, f'{stationnum}_initial.csv')\n",
    "    with open(csvname, \"w\",newline=\"\") as open_csv:\n",
    "        open_csv.write(reqreq.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J.) Now that we've received CSV tables for each station's ave temp values for the past 30 days, we may clean these CSV files up to have ~only~ a descriptive header and contents....so we may then concatenate all of the data into one CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we will create a new folder at the base of the working directory called 'CleanAveTempCSVs', which will store the 'cleaned up' csv tables for each station's 30 day ave. temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanavetemppath = os.path.join(wkdir, 'CleanAveTempCSVs')\n",
    "os.mkdir(cleanavetemppath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, running the function which lops off excess rows on each station's 30-day ave temp CSV, and gives the tables clean headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_initial.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6: # some of the stations do not have data for\n",
    "                              # the past 30 days; by selecting only CSVs\n",
    "                              # which have more than 6 rows, we should be\n",
    "            pass              # selecting all tables which returned data    \n",
    "        else:\n",
    "            station_avetemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "                                        # skipping first four rows,\n",
    "                                        # so df will only represent\n",
    "                                        # header and raw data.\n",
    "            updatedDF = station_avetemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",\n",
    "                \"deg.1\" : \"Longitude\",    # all dfs should have the same wonky\n",
    "                \"ft\" : \"Elevation\",       # variable names.\n",
    "                \"Unnamed: 4\" : \"Year\",\n",
    "                \"Unnamed: 5\" : \"Month\",\n",
    "                \"Unnamed: 6\" : \"Day\",\n",
    "                \"Degrees F\" : \"Avg Temp\",\n",
    "                \"Unnamed: 8\" : \"Avg Temp Flag\",\n",
    "                \"Degrees F.1\" : \"Normal Avg Temp\",\n",
    "                \"Degrees F.2\" : \"Departure from Normal Avg Temp\"})\n",
    "        \n",
    "            outcleancsv = os.path.join(wkdir,\n",
    "                                       'CleanAveTempCSVs',\n",
    "                                       f'{stationnum}_clean.csv')\n",
    "            updatedDF.to_csv(outcleancsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all stations 30-day ave temp CSVs into one 'master' concatenated CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\100_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\101_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\102_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\103_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\104_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\105_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\106_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\107_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\108_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\109_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\10_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\110_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\111_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\112_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\113_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\114_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\115_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\116_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\117_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\118_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\119_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\11_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\120_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\121_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\122_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\123_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\124_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\125_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\126_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\127_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\128_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\129_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\12_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\130_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\131_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\132_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\133_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\134_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\135_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\136_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\137_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\138_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\139_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\13_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\140_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\141_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\142_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\14_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\15_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\16_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\17_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\18_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\19_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\20_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\21_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\22_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\23_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\24_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\25_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\26_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\27_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\28_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\29_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\2_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\30_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\31_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\32_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\33_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\34_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\35_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\36_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\37_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\38_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\39_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\3_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\40_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\41_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\42_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\43_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\44_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\45_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\46_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\47_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\48_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\49_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\4_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\50_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\51_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\52_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\53_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\54_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\55_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\56_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\57_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\58_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\59_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\5_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\60_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\61_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\62_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\63_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\64_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\65_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\66_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\67_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\68_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\69_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\6_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\70_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\71_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\72_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\73_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\74_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\75_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\76_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\77_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\78_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\79_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\7_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\80_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\81_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\82_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\83_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\84_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\85_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\86_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\87_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\88_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\89_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\8_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\90_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\91_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\92_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\93_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\95_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\96_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\97_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\98_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\99_clean.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\CleanAveTempCSVs\\9_clean.csv has been imported.\n"
     ]
    }
   ],
   "source": [
    "avetemp30dayconcat = os.path.join(cleanavetemppath,\n",
    "                                  'avetemp30dayconcat.csv')\n",
    "\n",
    "allFiles = glob.glob(cleanavetemppath + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(avetemp30dayconcat, 'wb') as outfile:\n",
    "    for i, fname in enumerate(allFiles):\n",
    "        with open(fname, 'rb') as infile:\n",
    "            if i != 0:\n",
    "                infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "            print(fname + \" has been imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new folder which will contain CSVs describing each station's monthly mean ave temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "avetempgbpath = os.path.join(wkdir,\n",
    "                             'AveTempGroupbyCSVS')\n",
    "os.mkdir(avetempgbpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas 'GroupBy' function to aggregate all 30 days ave temp data for each station into one mean value; writing new CSVs to 'AveTempGroupbyCSVS' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_initial.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6:\n",
    "            pass\n",
    "        else:\n",
    "            station_avetemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "            updatedDF = station_avetemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",       # only changing header names that\n",
    "                \"deg.1\" : \"Longitude\",    # will be included in the groupby table\n",
    "                \"Degrees F\" : \"30 Day Avg Temp\"})\n",
    "            outavetempcsv = os.path.join(wkdir,\n",
    "                                         'AveTempGroupbyCSVS',\n",
    "                                         f'{stationnum}_avetempgroupby.csv')\n",
    "            groupbye = updatedDF.groupby(['Station Name','Latitude','Longitude']).agg({'30 Day Avg Temp': ['mean']}).reset_index()\n",
    "                            # grouping by mean will not affect the lat and long values,\n",
    "                            # because they are the same for every day\n",
    "            groupbye.columns = groupbye.columns.get_level_values(0)\n",
    "            groupbye.to_csv(outavetempcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of what one 'ave temp groupby' CSV file's contents look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>30 Day Avg Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>36.8081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station Name   Latitude  Longitude  30 Day Avg Temp\n",
       "0      Zeeland  46.013378 -99.687587          36.8081"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K.) Concatenating all stations' Ave Temp Groupby CSVS into one master CSV. This CSV contains each station name, its Latitude, Longitude, and mean 30 Day Ave Temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\100_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\101_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\102_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\103_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\104_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\105_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\106_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\107_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\108_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\109_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\10_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\110_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\111_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\112_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\113_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\114_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\115_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\116_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\117_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\118_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\119_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\120_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\121_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\122_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\123_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\124_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\125_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\126_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\127_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\128_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\129_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\12_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\130_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\131_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\132_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\133_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\134_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\135_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\136_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\137_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\138_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\139_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\13_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\140_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\141_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\142_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\14_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\15_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\16_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\18_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\19_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\20_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\21_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\23_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\24_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\25_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\26_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\27_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\28_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\29_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\2_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\30_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\31_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\33_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\34_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\35_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\36_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\37_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\38_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\3_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\40_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\41_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\43_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\44_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\45_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\46_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\47_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\48_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\4_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\50_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\52_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\53_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\54_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\56_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\57_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\58_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\59_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\5_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\60_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\61_avetempgroupby.csv has been imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\62_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\63_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\64_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\65_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\66_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\67_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\68_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\69_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\6_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\70_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\71_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\72_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\73_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\74_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\75_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\76_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\77_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\78_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\79_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\7_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\80_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\81_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\82_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\83_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\84_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\85_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\86_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\87_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\88_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\89_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\8_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\90_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\91_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\92_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\93_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\95_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\96_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\97_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\98_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\99_avetempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\AveTempGroupbyCSVS\\9_avetempgroupby.csv has been imported.\n"
     ]
    }
   ],
   "source": [
    "avetempGBconcat = os.path.join(avetempgbpath,\n",
    "                               'avetempGBconcat.csv')\n",
    "\n",
    "allFiles = glob.glob(avetempgbpath + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(avetempGBconcat, 'wb') as outfile:\n",
    "    for i, fname in enumerate(allFiles):\n",
    "        with open(fname, 'rb') as infile:\n",
    "            if i != 0:\n",
    "                infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "            print(fname + \" has been imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.) REQUESTING AND SEQUESTERING ABSOLUTE MIN AND MAX TEMPERATURE VALUES OVER THE PAST 30 DAYS FOR EACH WEATHER STATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning variables to the URL params NDAWN uses to specify what temperature variable should be used in the CSV return (max daily temp, min daily temp, ave daily temp, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtempvar = 'ddmxt'\n",
    "mintempvar = 'ddmnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L.) Creating new directories for the Max Temp and Min Temp station data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanmaxtemp = os.path.join(wkdir, 'CleanMaxTempCSVs')\n",
    "os.mkdir(cleanmaxtemp)\n",
    "\n",
    "cleanmintemp = os.path.join(wkdir, 'CleanMinTempCSVs')\n",
    "os.mkdir(cleanmintemp)\n",
    "\n",
    "maxtempgroupby = os.path.join(wkdir, 'MaxTempGroupbyCSVs')\n",
    "os.mkdir(maxtempgroupby)\n",
    "\n",
    "mintempgroupby = os.path.join(wkdir, 'MinTempGroupbyCSVs')\n",
    "os.mkdir(mintempgroupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M.) Sending requests to NDAWN for CSVs of daily MAXIMUM temp over 30 days for each of the weather stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    foldpath = os.path.join(stationsfolderpath, stationnum)\n",
    "    master_params = {\n",
    "        \"station\" : stationnum,\n",
    "        \"variable\" : maxtempvar,  # max temp\n",
    "        \"dfn\" : \"\",\n",
    "        \"year\" : \"2021\",     \n",
    "        \"ttype\" : \"daily\",    \n",
    "        \"quick_pick\" : \"30_d\",        \n",
    "        \"begin_date\" : formatteddate}  \n",
    "    \n",
    "    reqreq = requests.get(ndawn_csvtable_urlbase,\n",
    "                          params = master_params)\n",
    "    \n",
    "    csvname = os.path.join(foldpath,\n",
    "                           f'{stationnum}_maxtemp.csv') \n",
    "    with open(csvname, \"w\",newline=\"\") as open_csv:\n",
    "        open_csv.write(reqreq.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N.) Sending requests to NDAWN for CSVs of daily MINIMUM temp over 30 days for each of the weather stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    foldpath = os.path.join(stationsfolderpath, stationnum)\n",
    "    master_params = {\n",
    "        \"station\" : stationnum,\n",
    "        \"variable\" : mintempvar,  # !! MIN !! temp\n",
    "        \"dfn\" : \"\",\n",
    "        \"year\" : \"2021\",      \n",
    "        \"ttype\" : \"daily\",    \n",
    "        \"quick_pick\" : \"30_d\",        \n",
    "        \"begin_date\" : formatteddate}  \n",
    "    \n",
    "    reqreq = requests.get(ndawn_csvtable_urlbase,\n",
    "                          params = master_params)\n",
    "    \n",
    "    csvname = os.path.join(foldpath,\n",
    "                           f'{stationnum}_mintemp.csv')\n",
    "    with open(csvname, \"w\",newline=\"\") as open_csv:\n",
    "        open_csv.write(reqreq.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running previous function which lops off excess rows on each station's 30-day max temp CSV, and gives the tables clean headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_maxtemp.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6:             \n",
    "            pass   \n",
    "        else:\n",
    "            station_maxtemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "            updatedDF = station_maxtemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",\n",
    "                \"deg.1\" : \"Longitude\",    # all dfs should have the same wonky\n",
    "                \"ft\" : \"Elevation\",       # variable names.\n",
    "                \"Unnamed: 4\" : \"Year\",\n",
    "                \"Unnamed: 5\" : \"Month\",\n",
    "                \"Unnamed: 6\" : \"Day\",\n",
    "                \"Degrees F\" : \"Max Temp\",\n",
    "                \"Unnamed: 8\" : \"Max Temp Flag\",\n",
    "                \"Degrees F.1\" : \"Normal Max Temp\",\n",
    "                \"Degrees F.2\" : \"Departure from Normal Max Temp\",\n",
    "                \"Unnamed: 11\" : 'Departure from Normal Daily Maximum Air Temperature Flag'})\n",
    "        \n",
    "            outcleancsv = os.path.join(cleanmaxtemp,\n",
    "                                       f'{stationnum}_maxclean.csv')\n",
    "            updatedDF.to_csv(outcleancsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doing the same as above for each station's 30-day MINIMUM temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_mintemp.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6:             \n",
    "            pass   \n",
    "        else:\n",
    "            station_mintemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "            updatedDF = station_mintemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",\n",
    "                \"deg.1\" : \"Longitude\",    \n",
    "                \"ft\" : \"Elevation\",     \n",
    "                \"Unnamed: 4\" : \"Year\",\n",
    "                \"Unnamed: 5\" : \"Month\",\n",
    "                \"Unnamed: 6\" : \"Day\",\n",
    "                \"Degrees F\" : \"Min Temp\",\n",
    "                \"Unnamed: 8\" : \"Min Temp Flag\",\n",
    "                \"Degrees F.1\" : \"Normal Min Temp\",\n",
    "                \"Degrees F.2\" : \"Departure from Normal Min Temp\",\n",
    "                \"Unnamed: 11\" : 'Departure from Normal Daily Min Air Temperature Flag'})\n",
    "        \n",
    "            outcleancsv = os.path.join(cleanmintemp,\n",
    "                                       f'{stationnum}_minclean.csv')\n",
    "            updatedDF.to_csv(outcleancsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of what a 'clean' 30-day minimum temp CSV looks like for a given station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Min Temp</th>\n",
       "      <th>Min Temp Flag</th>\n",
       "      <th>Normal Min Temp</th>\n",
       "      <th>Departure from Normal Min Temp</th>\n",
       "      <th>Departure from Normal Daily Min Air Temperature Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>12.920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-8.080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>24.978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>19.416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>26.767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.767</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>20.849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>14.828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-8.172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-15.840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>22.498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>11.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-12.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-17.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-13.232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28.742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.742</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26.942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>30.042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.042</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>35.656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.656</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>30.808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>26.476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>23.234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-4.766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11.588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-16.412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20.968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-8.032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>23.355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-5.645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>19.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-10.800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>22.199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-7.801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>27.397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-3.603</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>30.495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>18.387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-12.613</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>20.601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-11.399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>7.754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-24.246</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Zeeland</td>\n",
       "      <td>46.013378</td>\n",
       "      <td>-99.687587</td>\n",
       "      <td>2070</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>6.296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-26.704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station Name   Latitude  Longitude  Elevation  Year  Month  Day  Min Temp  \\\n",
       "0       Zeeland  46.013378 -99.687587       2070  2021      3   22    12.920   \n",
       "1       Zeeland  46.013378 -99.687587       2070  2021      3   23    24.978   \n",
       "2       Zeeland  46.013378 -99.687587       2070  2021      3   24    19.416   \n",
       "3       Zeeland  46.013378 -99.687587       2070  2021      3   25    26.767   \n",
       "4       Zeeland  46.013378 -99.687587       2070  2021      3   26    20.849   \n",
       "5       Zeeland  46.013378 -99.687587       2070  2021      3   27    14.828   \n",
       "6       Zeeland  46.013378 -99.687587       2070  2021      3   28     7.160   \n",
       "7       Zeeland  46.013378 -99.687587       2070  2021      3   29    22.498   \n",
       "8       Zeeland  46.013378 -99.687587       2070  2021      3   30    11.120   \n",
       "9       Zeeland  46.013378 -99.687587       2070  2021      3   31     6.008   \n",
       "10      Zeeland  46.013378 -99.687587       2070  2021      4    1    11.768   \n",
       "11      Zeeland  46.013378 -99.687587       2070  2021      4    2    31.199   \n",
       "12      Zeeland  46.013378 -99.687587       2070  2021      4    3    28.742   \n",
       "13      Zeeland  46.013378 -99.687587       2070  2021      4    4    26.942   \n",
       "14      Zeeland  46.013378 -99.687587       2070  2021      4    5    30.042   \n",
       "15      Zeeland  46.013378 -99.687587       2070  2021      4    6    35.656   \n",
       "16      Zeeland  46.013378 -99.687587       2070  2021      4    7    30.808   \n",
       "17      Zeeland  46.013378 -99.687587       2070  2021      4    8    26.476   \n",
       "18      Zeeland  46.013378 -99.687587       2070  2021      4    9    23.234   \n",
       "19      Zeeland  46.013378 -99.687587       2070  2021      4   10    11.588   \n",
       "20      Zeeland  46.013378 -99.687587       2070  2021      4   11    20.968   \n",
       "21      Zeeland  46.013378 -99.687587       2070  2021      4   12    23.355   \n",
       "22      Zeeland  46.013378 -99.687587       2070  2021      4   13    19.200   \n",
       "23      Zeeland  46.013378 -99.687587       2070  2021      4   14    22.199   \n",
       "24      Zeeland  46.013378 -99.687587       2070  2021      4   15    27.397   \n",
       "25      Zeeland  46.013378 -99.687587       2070  2021      4   16    30.495   \n",
       "26      Zeeland  46.013378 -99.687587       2070  2021      4   17    18.387   \n",
       "27      Zeeland  46.013378 -99.687587       2070  2021      4   18    20.601   \n",
       "28      Zeeland  46.013378 -99.687587       2070  2021      4   19     7.754   \n",
       "29      Zeeland  46.013378 -99.687587       2070  2021      4   20     6.296   \n",
       "\n",
       "    Min Temp Flag  Normal Min Temp  Departure from Normal Min Temp  \\\n",
       "0             NaN             21.0                          -8.080   \n",
       "1             NaN             21.0                           3.978   \n",
       "2             NaN             22.0                          -2.584   \n",
       "3             NaN             22.0                           4.767   \n",
       "4             NaN             22.0                          -1.151   \n",
       "5             NaN             23.0                          -8.172   \n",
       "6             NaN             23.0                         -15.840   \n",
       "7             NaN             24.0                          -1.502   \n",
       "8             NaN             24.0                         -12.880   \n",
       "9             NaN             24.0                         -17.992   \n",
       "10            NaN             25.0                         -13.232   \n",
       "11            NaN             25.0                           6.199   \n",
       "12            NaN             26.0                           2.742   \n",
       "13            NaN             26.0                           0.942   \n",
       "14            NaN             26.0                           4.042   \n",
       "15            NaN             27.0                           8.656   \n",
       "16            NaN             27.0                           3.808   \n",
       "17            NaN             28.0                          -1.524   \n",
       "18            NaN             28.0                          -4.766   \n",
       "19            NaN             28.0                         -16.412   \n",
       "20            NaN             29.0                          -8.032   \n",
       "21            NaN             29.0                          -5.645   \n",
       "22            NaN             30.0                         -10.800   \n",
       "23            NaN             30.0                          -7.801   \n",
       "24            NaN             31.0                          -3.603   \n",
       "25            NaN             31.0                          -0.505   \n",
       "26            NaN             31.0                         -12.613   \n",
       "27            NaN             32.0                         -11.399   \n",
       "28            NaN             32.0                         -24.246   \n",
       "29            NaN             33.0                         -26.704   \n",
       "\n",
       "    Departure from Normal Daily Min Air Temperature Flag  \n",
       "0                                                 NaN     \n",
       "1                                                 NaN     \n",
       "2                                                 NaN     \n",
       "3                                                 NaN     \n",
       "4                                                 NaN     \n",
       "5                                                 NaN     \n",
       "6                                                 NaN     \n",
       "7                                                 NaN     \n",
       "8                                                 NaN     \n",
       "9                                                 NaN     \n",
       "10                                                NaN     \n",
       "11                                                NaN     \n",
       "12                                                NaN     \n",
       "13                                                NaN     \n",
       "14                                                NaN     \n",
       "15                                                NaN     \n",
       "16                                                NaN     \n",
       "17                                                NaN     \n",
       "18                                                NaN     \n",
       "19                                                NaN     \n",
       "20                                                NaN     \n",
       "21                                                NaN     \n",
       "22                                                NaN     \n",
       "23                                                NaN     \n",
       "24                                                NaN     \n",
       "25                                                NaN     \n",
       "26                                                NaN     \n",
       "27                                                NaN     \n",
       "28                                                NaN     \n",
       "29                                                NaN     "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updatedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O.) Using Pandas 'GroupBy' function to grab the maximum value among all 30 days of Max temp data for each; writing new CSVs to 'MaxTempGroupbyCSVs' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_maxtemp.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6:\n",
    "            pass\n",
    "        else:\n",
    "            station_maxtemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "            updatedDF = station_maxtemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",\n",
    "                \"deg.1\" : \"Longitude\",\n",
    "                \"Degrees F\" : \"30 Day Max Temp\"})\n",
    "            outmaxtempcsv = os.path.join(wkdir,\n",
    "                                         'MaxTempGroupbyCSVs',\n",
    "                                         f'{stationnum}_maxtempgroupby.csv')\n",
    "            \n",
    "            groupbye = updatedDF.groupby(['Station Name',\n",
    "                                         'Latitude',\n",
    "                                         'Longitude']).agg({'30 Day Max Temp': ['max']}).reset_index()\n",
    "                                            # grouping by MAX this time, to find the maximum\n",
    "                                            # value between the 30 days..~\n",
    "                                            # Grouping by max will again, not affect the lat and long\n",
    "                                            # values, because they are all the same for each day.\n",
    "            groupbye.columns = groupbye.columns.get_level_values(0)\n",
    "            groupbye.to_csv(outmaxtempcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.) Using Pandas 'GroupBy' function to grab the minimum value among all 30 days of Min temp data for each; writing new CSVs to 'MinTempGroupbyCSVs' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stationnum in just_stationnumbers:\n",
    "    folderpath = os.path.join(stationsfolderpath,\n",
    "                              stationnum)\n",
    "    itercsvname = os.path.join(folderpath,\n",
    "                               f'{stationnum}_mintemp.csv')\n",
    "    with open(itercsvname, 'r',newline=\"\") as itercsv:\n",
    "        rowitems = []\n",
    "        for row in itercsv:\n",
    "            rowitems.append(row)\n",
    "        if len(rowitems) < 6:\n",
    "            pass\n",
    "        else:\n",
    "            station_mintemp_df = pd.read_csv(itercsvname,\n",
    "                                             skiprows=4)\n",
    "            updatedDF = station_mintemp_df.rename(columns={\n",
    "                \"Unnamed: 0\": \"Station Name\",\n",
    "                \"deg\" : \"Latitude\",\n",
    "                \"deg.1\" : \"Longitude\",\n",
    "                \"Degrees F\" : \"30 Day Min Temp\"}) # minimum this time..\n",
    "            outmintempcsv = os.path.join(wkdir,\n",
    "                                         'MinTempGroupbyCSVs',\n",
    "                                         f'{stationnum}_mintempgroupby.csv')\n",
    "            \n",
    "            groupbye = updatedDF.groupby(['Station Name',\n",
    "                                         'Latitude',\n",
    "                                         'Longitude']).agg({'30 Day Min Temp': ['min']}).reset_index()\n",
    "                                            # grouping by 'MIN' this time !!!!!~!~\n",
    "            groupbye.columns = groupbye.columns.get_level_values(0)\n",
    "            groupbye.to_csv(outmintempcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.) Concatenating all station MAX Temp Groupby CSVs into one CSV. This CSV contains each station name, its Latitude, Longitude, and maximum temp over 30 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\100_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\101_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\102_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\103_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\104_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\105_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\106_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\107_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\108_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\109_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\10_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\110_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\111_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\112_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\113_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\114_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\115_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\116_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\117_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\118_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\119_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\120_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\121_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\122_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\123_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\124_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\125_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\126_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\127_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\128_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\129_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\12_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\130_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\131_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\132_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\133_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\134_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\135_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\136_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\137_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\138_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\139_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\13_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\140_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\141_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\142_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\14_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\15_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\16_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\18_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\19_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\20_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\21_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\23_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\24_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\25_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\26_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\27_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\28_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\29_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\2_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\30_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\31_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\33_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\34_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\35_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\36_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\37_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\38_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\3_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\40_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\41_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\43_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\44_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\45_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\46_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\47_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\48_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\4_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\50_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\52_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\53_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\54_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\56_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\57_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\58_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\59_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\5_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\60_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\61_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\62_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\63_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\64_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\65_maxtempgroupby.csv has been imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\66_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\67_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\68_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\69_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\6_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\70_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\71_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\72_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\73_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\74_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\75_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\76_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\77_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\78_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\79_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\7_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\80_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\81_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\82_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\83_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\84_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\85_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\86_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\87_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\88_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\89_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\8_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\90_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\91_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\92_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\93_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\95_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\96_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\97_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\98_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\99_maxtempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MaxTempGroupbyCSVs\\9_maxtempgroupby.csv has been imported.\n"
     ]
    }
   ],
   "source": [
    "maxtempGBconcat = os.path.join(maxtempgroupby,\n",
    "                               'maxtempGBconcat.csv')\n",
    "\n",
    "allFiles = glob.glob(maxtempgroupby + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(maxtempGBconcat, 'wb') as outfile:\n",
    "    for i, fname in enumerate(allFiles):\n",
    "        with open(fname, 'rb') as infile:\n",
    "            if i != 0:\n",
    "                infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "            print(fname + \" has been imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R.) Concatenating all station MIN Temp Groupby CSVs into one CSV. This CSV contains each station name, its Latitude, Longitude, and minimum temp over 30 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\100_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\101_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\102_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\103_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\104_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\105_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\106_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\107_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\108_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\109_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\10_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\110_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\111_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\112_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\113_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\114_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\115_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\116_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\117_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\118_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\119_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\120_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\121_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\122_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\123_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\124_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\125_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\126_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\127_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\128_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\129_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\12_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\130_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\131_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\132_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\133_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\134_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\135_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\136_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\137_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\138_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\139_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\13_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\140_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\141_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\142_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\14_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\15_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\16_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\18_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\19_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\20_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\21_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\23_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\24_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\25_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\26_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\27_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\28_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\29_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\2_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\30_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\31_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\33_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\34_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\35_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\36_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\37_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\38_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\3_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\40_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\41_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\43_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\44_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\45_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\46_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\47_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\48_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\4_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\50_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\52_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\53_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\54_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\56_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\57_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\58_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\59_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\5_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\60_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\61_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\62_mintempgroupby.csv has been imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\63_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\64_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\65_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\66_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\67_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\68_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\69_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\6_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\70_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\71_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\72_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\73_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\74_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\75_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\76_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\77_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\78_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\79_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\7_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\80_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\81_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\82_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\83_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\84_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\85_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\86_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\87_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\88_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\89_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\8_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\90_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\91_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\92_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\93_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\95_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\96_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\97_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\98_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\99_mintempgroupby.csv has been imported.\n",
      "C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\MinTempGroupbyCSVs\\9_mintempgroupby.csv has been imported.\n"
     ]
    }
   ],
   "source": [
    "mintempGBconcat = os.path.join(mintempgroupby,\n",
    "                               'mintempGBconcat.csv')\n",
    "\n",
    "allFiles = glob.glob(mintempgroupby + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(mintempGBconcat, 'wb') as outfile:\n",
    "    for i, fname in enumerate(allFiles):\n",
    "        with open(fname, 'rb') as infile:\n",
    "            if i != 0:\n",
    "                infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "            print(fname + \" has been imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.) USING ARCPY TO CREATE POINT FEATURE CLASSES OUT OF CONCATENATED CSV FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S.) Setting up directory to store Arcpy-related files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpro_folder = os.path.join(wkdir,'ARCPRO')\n",
    "os.mkdir(arcpro_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = wkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### String which accesses WGS84 GCS when inputted into the CRS param of Arcpy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84_GCS = \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T.) Using the Arcpy Management \"XYTableToPoint\" function to convert the 'Ave Temp Groupby Concatenation' CSV into a point feature class, using the Longitude and Latitude fields for the X and Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\ARCPRO\\weatherstations_avetemp.shp<h2>Messages</h2>Start Time: Thursday, April 22, 2021 8:07:52 AM<br/>Succeeded at Thursday, April 22, 2021 8:07:53 AM (Elapsed Time: 0.80 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\\\\\Users\\\\\\\\michaelfelzan\\\\\\\\Documents\\\\\\\\arc ii lab IV\\\\2021-04-21_NDAWN\\\\ARCPRO\\\\weatherstations_avetemp.shp'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avetempstations = os.path.join(arcpro_folder, \"weatherstations_avetemp\")\n",
    "\n",
    "arcpy.management.XYTableToPoint(avetempGBconcat,\n",
    "                                avetempstations,\n",
    "                                \"Longitude\",\n",
    "                                \"Latitude\", \n",
    "                             None,\n",
    "                                wgs84_GCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~ ~ ~ ~ ~ ~ ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~ ~ ~ ~ ~ ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instead of joining the Max Temp and Min Temp tables to the point feature class created in the above step, I decided , because those tables `also` contain Lat and Long fields, it would be less steps to just create two more point feature classes -- one for all stations' max temps over 30 days, and another for all stations' min temp over 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~ ~ ~ ~ ~ .,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.) Using the Arcpy Management \"XYTableToPoint\" function to convert the 'Max Temp Groupby Concatenation' CSV into its own point feature class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\ARCPRO\\weather_stations_maxtemp.shp<h2>Messages</h2>Start Time: Thursday, April 22, 2021 8:09:33 AM<br/>Succeeded at Thursday, April 22, 2021 8:09:34 AM (Elapsed Time: 0.86 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\\\\\Users\\\\\\\\michaelfelzan\\\\\\\\Documents\\\\\\\\arc ii lab IV\\\\2021-04-21_NDAWN\\\\ARCPRO\\\\weather_stations_maxtemp.shp'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxtempstations = os.path.join(arcpro_folder, \"weather_stations_maxtemp\")\n",
    "\n",
    "arcpy.management.XYTableToPoint(maxtempGBconcat,\n",
    "                                maxtempstations,\n",
    "                                \"Longitude\",\n",
    "                                \"Latitude\", \n",
    "                                None,\n",
    "                                wgs84_GCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.) Using the Arcpy Management \"XYTableToPoint\" function to convert the 'Min Temp Groupby Concatenation' CSV into its own point feature class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\ARCPRO\\weather_stations_mintemp.shp<h2>Messages</h2>Start Time: Thursday, April 22, 2021 8:10:00 AM<br/>Succeeded at Thursday, April 22, 2021 8:10:00 AM (Elapsed Time: 0.82 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\\\\\Users\\\\\\\\michaelfelzan\\\\\\\\Documents\\\\\\\\arc ii lab IV\\\\2021-04-21_NDAWN\\\\ARCPRO\\\\weather_stations_mintemp.shp'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mintempstations = os.path.join(arcpro_folder, \"weather_stations_mintemp\")\n",
    "\n",
    "arcpy.management.XYTableToPoint(mintempGBconcat,\n",
    "                                mintempstations,\n",
    "                                \"Longitude\",\n",
    "                                \"Latitude\", \n",
    "                                None,\n",
    "                                wgs84_GCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### designating path to weatherstations_avetemp.shp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "avetempstations_SHP = os.path.join(arcpro_folder, \"weatherstations_avetemp.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W.) Creating file geodatabase in 'ARCPRO' folder ('grid' files, which the Kriging function will output in the next step, have(?) to be stored in esri filegeodatabases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\\\Users\\\\michaelfelzan\\\\Documents\\\\arc ii lab IV\\2021-04-21_NDAWN\\ARCPRO\\Lab4_fGDB.gdb<h2>Messages</h2>Start Time: Thursday, April 22, 2021 8:30:59 AM<br/>Succeeded at Thursday, April 22, 2021 8:30:59 AM (Elapsed Time: 0.43 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\\\\\Users\\\\\\\\michaelfelzan\\\\\\\\Documents\\\\\\\\arc ii lab IV\\\\2021-04-21_NDAWN\\\\ARCPRO\\\\Lab4_fGDB.gdb'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.CreateFileGDB_management(arcpro_folder, \"Lab4_fGDB.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab4GBD = os.path.join(arcpro_folder, \"Lab4_fGDB.gdb\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.) USING ARCPY TO SPATIALLY INTERPOLATE MONTHLY AVE, MAX, AND MIN TEMPERATURE VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X.) Running arcpy.sa.Kriging() function on Ave Temp weather stations FC, outputting interpolated surface map of average monthly temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kriging(in_point_features, \n",
    "#         z_field, \n",
    "#        semiVariogram_props, \n",
    "#        {cell_size}, \n",
    "#        {search_radius}, \n",
    "#        {out_variance_prediction_raster})\n",
    "\n",
    "\n",
    "avetemp_OrdKrig = os.path.join(lab4GBD, \"avetemp_OrdKrig\")\n",
    "\n",
    "out_surface_raster = arcpy.sa.Kriging(avetempstations_SHP,\n",
    "                                      \"F30_Day_Av\",\n",
    "                                      \"Spherical 0.014478 # # #\",\n",
    "                                      0.014477764,\n",
    "                                      \"VARIABLE 12\",\n",
    "                                      None)\n",
    "                  \n",
    "out_surface_raster.save(avetemp_OrdKrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y.) Running arcpy.sa.Kriging() function on Max Temp weather stations FC, outputting interpolated surface map of monthly max temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtempstations_SHP = os.path.join(arcpro_folder, \"weather_stations_maxtemp.shp\")\n",
    "maxtemp_OrdKrig = os.path.join(lab4GBD, \"maxtemp_OrdKrig\")\n",
    "\n",
    "out_surface_raster = arcpy.sa.Kriging(maxtempstations_SHP,\n",
    "                                      \"F30_Day_Ma\",\n",
    "                                      \"Spherical 0.014478 # # #\",\n",
    "                                      0.014477764,\n",
    "                                      \"VARIABLE 12\",\n",
    "                                      None)\n",
    "                  \n",
    "out_surface_raster.save(maxtemp_OrdKrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.) Running arcpy.sa.Kriging() function on Min Temp weather stations FC, outputting interpolated surface map of monthly minimum temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mintempstations_SHP = os.path.join(arcpro_folder, \"weather_stations_mintemp.shp\")\n",
    "mintemp_OrdKrig = os.path.join(lab4GBD, \"mintemp_OrdKrig\")\n",
    "\n",
    "out_surface_raster = arcpy.sa.Kriging(mintempstations_SHP,\n",
    "                                      \"F30_Day_Mi\",\n",
    "                                      \"Spherical 0.014478 # # #\",\n",
    "                                      0.014477764,\n",
    "                                      \"VARIABLE 12\",\n",
    "                                      None)\n",
    "                  \n",
    "out_surface_raster.save(mintemp_OrdKrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
